env_name: LunarLanderContinuous-v2
ep_len: 1000
exp_name: q3_b40000_r0.005
n_iter: 100
mpc_horizon: 10
mpc_num_action_sequences: 1000
mpc_action_sampling_strategy: random
cem_iterations: 4
cem_num_elites: 5
cem_alpha: 1
add_sl_noise: true
batch_size_initial: 5000
batch_size: 40000
train_batch_size: 512
eval_batch_size: 400
seed: 1
no_gpu: false
which_gpu: 0
video_log_freq: -1
scalar_log_freq: 1
save_params: false
rl_alg: reinforce
computation_graph_args:
  learning_rate: 0.005
  n_layers: 2
  size: 64
  ensemble_size: 3
  num_grad_steps_per_target_update: 1
  num_target_updates: 1
estimate_advantage_args:
  discount: 0.99
  gae_lambda: 0.9
  gae: false
  standardize_advantages: true
  reward_to_go: true
  nn_baseline: true
train_args:
  num_agent_train_steps_per_iter: 1
  num_critic_updates_per_agent_update: 1
  num_actor_updates_per_agent_update: 1
  discrete: false
  ob_dim: 0
  ac_dim: 0
